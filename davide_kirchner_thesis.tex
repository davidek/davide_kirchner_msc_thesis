%\documentclass[12pt,a4paper,oneside]{book}
%\documentclass[12pt,a4paper,twoside]{book}
\documentclass[11pt,a4paper,twoside,titlepage,openany]{book}
\usepackage[english]{babel}

\usepackage[hidelinks,breaklinks]{hyperref}  % added

\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{amssymb}
%\usepackage{natbib}
\usepackage[numbers]{natbib}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{color}
\usepackage{comment}

% added
\usepackage{listings}
 \lstset{basicstyle=\footnotesize\ttfamily}
 %\lstset{basicstyle=\footnotesize,keywordstyle=\color{blue},}
 %\lstset{basicstyle=\small\ttfamily,frame=single}
 \AtBeginDocument{\DeclareCaptionSubType{lstlisting}} % must stay between listings and subcaption
\usepackage{subcaption}
\usepackage[super]{nth}
%\usepackage[xindy,toc]{glossaries}
\usepackage[nottoc,chapter]{tocbibind} % ToC item for Bibliography at chapter level [no ToC item for ToC]
\usepackage[boxed,algochapter,vlined]{algorithm2e}
\usepackage{indentfirst}  % Indent first line of first paragraph of chapters/sections/...
\usepackage[inline]{enumitem}
 \newlist{inlineenum}{enumerate*}{1}
 \setlist[inlineenum]{label=\textit{\roman*})}
\usepackage{tikz}
\renewcommand{\bottomfraction}{0.6}  %
\renewcommand{\topfraction}{0.7}     %  Fit more figures in text pages
\newcommand{\mono}[1]{\texttt{#1}}

% TODO notes
\usepackage{xcolor}  % would anyway be imported by todonotes
\colorlet{lightorange}{orange!40}  % 40% orange, 60% white
\usepackage[colorinlistoftodos,linecolor=orange,backgroundcolor=lightorange]{todonotes}
%% Usage: \todo{margin note} or \todo[inline]{note in a full-width box}

\usepackage{csvsimple}  % read csv to table
\usepackage{booktabs}   % table styling

% Glossary
\usepackage[xindy,toc]{glossaries}  % nomain allows for 
%\loadglsentries[main]{SDN-glossary}
\include{SDN-glossary}
\makeglossaries

% for allowing forced newlines inside table header cells
% from http://tex.stackexchange.com/a/19678/25479
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\bibliographystyle{alpha}
%\bibliographystyle{plain}
%\bibliographystyle{plainnat}  % allows \citeauthor but still uses numbering with [numbers]
%\bibliographystyle{unsrtnat}  % allows \citeauthor but still uses numbering with [numbers]
%\usepackage[all]{nowidow}  % Tries to prevent widow lines


% vvv  Acknowledgemts in cima  vvv
\makeatletter
\newcommand\ackname{Acknowledgements}
\newenvironment{acknowledgements}{
  \newpage
  \thispagestyle{empty}
  \null\vfil
  \@beginparpenalty\@lowpenalty
  \begin{center}
    % \bfseries \ackname  % tolto da me
    \@endparpenalty\@M
  \end{center}}
{\par\vfil\null\endtitlepage}
\makeatother
% ^^^  Acknowledgemts in cima  ^^^

%glossary
%\makeglossaries
%\newacronym{GIS}{GIS}{Geographical Information System}
%\newacronym{fromto}{SD pair}{Source-Destination node pair}


% This is needed in order NOT to print blank pages, even if a chapter begins at odd page
% even if in twoside. When document will be done, might be re-inserted
%\let\cleardoublepage\clearpage

\begin{document}

\begin{titlepage}
  \begin{center}
    \begin{Large}University of Trento\\\end{Large}
    Department of Information Engineering and Computer Science
    \vspace{10pt}
    %\begin{figure}[htb]
    \begin{figure}[h!]
      \begin{center}
        % \includegraphics[width=3cm]{img/sigillo_unitn.eps}
        % \includegraphics[width=3cm]{img/unitn_logo.eps}
        \includegraphics[width=3cm]{img/unitn_logo.pdf}
      \end{center}
    \end{figure}

    Master degree course in Computer Science

    \vspace{10pt}
    \line(1,0){338}
    \vspace{10pt}

    Final Thesis\\
  \end{center}

  \vspace{3cm}

  \begin{center}
    \begin{Large}
      Performance evaluation and design of a software Information Centric
      Networking router\\\end{Large}
    \vspace{3cm}
  \end{center}

  \noindent
  \begin{minipage}[t]{.7\linewidth}
    Supervisors:\\ 
    \textbf{Prof. Renato Lo Cigno}\\
    \textbf{Prof. Luca Valcarenghi}
  \end{minipage}%
  \begin{minipage}[t]{.25\linewidth}
    %~\\
    Graduant:\\
    \textbf{Davide Kirchner}
  \end{minipage}

  \vspace{2cm}
  \begin{center}
    Academic year 2014-2015
  \end{center}
\end{titlepage}

\tableofcontents

%\printglossaries

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\begin{acknowledgements}

This work was developed in the context of a stage and junior programmer job position at \emph{Predictive Models for Biomedicine and Environment} (MPBA) unit at \emph{Fondazione Bruno Kessler} research center.

I would like to express my gratitude to Cesare Furlanello, head of unit at MPBA, and to Alberto Montresor, associate professor at the University of Trento, for supervising my  work.

%This work was possible thanks to the effort of Cesare Furlanello and all the colleagues at \emph{Predictive Models for Biomedicine and Environment} (MPBA) unit at \emph{Fondazione Bruno Kessler} who contributed to the results I have achieved.
%I would also like to thank professor Alberto Montresor for supervising me in this work.
\end{acknowledgements}
\end{comment}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Summary}
\addcontentsline{toc}{chapter}{Summary}

%\vspace{-.7cm}  % prevent abstract from using 3 pages. Actually ugly

%% FOOTNOTE EXAMPLE
% The results of this work can be used in the epidemiological analysis phase of \emph{SicurSkiWeb}%
% \footnote{\emph{SicurSkiWeb} is developed by \emph{MPBA} (\emph{Predictive Models for Biomedicine and Environment}) unit at \emph{Fondazione Bruno Kessler} and the Questura of Trento (Ski Patrol Unit)},
% a project which aims at providing a spatial decision system for monitoring and improving safety on ski slopes. December \nth{6}.

%\vspace{-.2cm}  % prevent abstract from using 3 pages. Actually ugly

%  SUBFIGURE EXAMPLE
%\begin{figure}[htb]
%  \centering
%  \begin{subfigure}{.5\textwidth}
%    \centering
%    \frame{
%      \begin{tikzpicture}
%        \path [clip] (0,0) rectangle (.95\linewidth,.90\linewidth);
%        \node (graph) at (.5\linewidth,.5\linewidth) [yshift=-.5cm]
%          {\includegraphics[width=.95\linewidth]{img/maps/igraph_graph.pdf}};
%        % \node (pict) at (0,.90\linewidth) [anchor=north west,xshift=.1cm,yshift=-.1cm]
%        %   {\frame{\includegraphics[width=.7\linewidth]{img/skiarea_mdc_pinzolo_drowing.jpg}}};
%      \end{tikzpicture}
%    }
%    %\caption*{Slopes topology graph (Pinzolo).\\~}
%  \end{subfigure}%
%  \begin{subfigure}{.5\textwidth}
%    \centering
%    \frame{
%      \begin{tikzpicture}
%        \path [use as bounding box] (0,0) rectangle (.95\linewidth,.90\linewidth);
%        \node at (.5\linewidth,.5\linewidth)
%          {\includegraphics[width=\linewidth]{img/traffic/brenta_groups_bw.pdf}};
%      \end{tikzpicture}
%    }
%    %\caption*{Travel time distributions on Brenta slope for different groups types.}
%  \end{subfigure}
%  \caption[]{Left panel: slopes topology graph for Pinzolo skiing area. Right panel: travel time distributions on Brenta slope for different groups types.}
%\end{figure}


%\vspace{-.6cm}  % prevent abstract from using 3 pages. Actually ugly



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\todo[inline]{General intro}

\section{Software defined networking}
The growing availability of high-performance commodity off-the-shelf %\gls{COTS}
hardware has made software more and more competitive even for performance-critical functions that have been traditionally implemented with dedicated hardware: in the networking domain, affordable 10 Gbps network cards together with multi-core CPUs and GPUs were the key enablers for this shift.

%\begin{figure}[htb]
%  \begin{center}
%    \frame{\includegraphics[width=.6\textwidth]{/tmp/figure_1.pdf}}
%    \caption[Available maps for Pinzolo ski area]{Available maps for Pinzolo ski area.}
%    \label{fig:map-input}
%  \end{center}
%\end{figure}

%The main advantage for choosing software over hardware is of course the greater flexibility: software allows for much quicker development-deployment cycles and simplifies the management enabling increasingly complex functions to be pushed towards the core of the networks.
While this transition might not be worth for IP backbone routing, where the scale fully justifies the development and production costs of dedicated hardware reaching the limits of routing capabilities, for applications ranging from firewalls to experimental routing protocols and even intra-datacenter routing, it's reasonable to trade-off some performance for increased flexibility and decreased development costs.
Back in 2000, these motivations brought Kohler et al. \cite{click} to develop the \emph{Click Modular Router}, a complete and extensible framework for setting up complex network functionalities, which keeps receiving a lot of attention from the \gls{SDN} research community, as detailed hereafter. Click allows a middlebox application to be described declaratively as a directed graph of simple functionalities, \emph{elements}, that process each packet in cascade (one example is provided in listing~\ref{lst:augustus.clicl}).

\paragraph{High-speed packet I/O} Together with new hardware, one key improvement that has enabled the recent performance boost of software-based routing was the introduction of high-speed packet I/O libraries, all of which provide a way to bypass the OS basic network stack, which is flow-oriented and might involve a packet being copied a number of times in its way from the NIC card to the userspace memory. %in order to optimize for packet-oriented processing.

Among these libraries, the most recent are the open-source netmap, proposed by Rizzo \cite{netmap} and DPDK (Data Plane Development Kit), initially developed at Intel for their NICs and later open sourced with a broader hardware support \cite{dpdk}%
%\todo{others are psio (PacketShader I/O Engine) and PF RING ZC but I did't look into them deeply, they seem relatively outdated}
: both of them optimize the I/O management to allow for zero-copy packet processing so that the software stack never makes copies of the packet's content, relying solely the \gls{DMA} write operation performed by the input NIC card to a shared buffer that is directly accessed by the application code and, in case the packet is forwarded, by the output NIC card.

Other features shared by both libraries are:
\begin{inlineenum}
\item the possibility to receive in batches, thus amortising the cost of the required syscalls and interrupts management among a batch of packets; and
\item the option to leverage on modern NIC cards' hardware multi-queue system, allowing the incoming traffic from one card to be split among multiple threads that may run on different cores.
\end{inlineenum}
The two libraries achieve these goals with different architectures: while netmap runs as a kernel module and relies on mmap to share the buffers with the userspace application, DPDK's core runs in userspace.
Performance-wise, the two libraries are comparable and both were shown to outperform the basic Linux and BSD network stacks; DPDK has been documented to behave slightly better in some applications \cite{fastclick}.


\paragraph{Routing software frameworks} On top op these libraries, higher-level frameworks ease the implementation of custom high-speed router/middlebox functionalities, bundled with commonly used components and sample applications, often directly or indirectly based on Click \cite{click}.
Barbette et al. \cite{fastclick} approached this by forking Click and addressing its bottlenecks one by one in the light of the newly available hardware and fast I/O libraries, resulting in the open-source FastClick. Another approach, pursued by Kim et al. \cite{nba}, fully implemented a closed-source Click-like middlebox programming framework called NBA (Netrowk Balancing Act), re-using (and extending) only the original Click configuration parser. %\todo{These 2 seem the most recent, taking some ideas from DoubleClick and Snap}
FastClick and NBA share a number of features: they
\begin{inlineenum}
\item fully exploit zero-copy I/O and hardware multi-queuing;
\item take advantage of I/O batching and bring the idea further to computation batching;
\item use a run-to-completion (also called full-push, in contrast with pipelined or push-pull) execution model, meaning that a single thread will handle all the components that act on the same packet batch; and
\item handle computation and I/O in a \gls{NUMA}-aware fashion.
\end{inlineenum}
Moreover, NBA poses a strong focus on exploiting heterogeneous co-processors such as GPUs, allowing for an equivalent CPU-only implementation of each \emph{offloadable} component: it is then capable of dynamically balance (hence the name) the computation among the CPU and the co-processors, which are only used under heavy workload, as they negatively impacts latency. In their tests, NBA authors ran a sample IPv4 routing application on a machine with 16-cores, 4 network cards with two 10 Gbps ports each (4x 2x 10 Gbps) and 5 GPUs: the system yielded about 60 Gbps with 64B frames (corresponding to about 89 \gls{Mpps}\todo{did they measure at phy level?}). On their side, the FastClick authors obtained a 30 Gbps throughput (corresponding to about 45 \gls{Mpps}?\todo{same?}) with a router application running on 4 cores and 2x 2x 10 Gbps NIC cards with the same minimal frame size.

\paragraph{Virtualization} Another interesting application of software routers is the possibility to run network functions on virtual machines (VMs), which goes under the name of \acrfull{NFV}.
Still allowing the flexibility introduced with \gls{SDN}, this is attractive to the cloud business in that it allows independent network functionalities to be deployed on the same hardware in isolation (both from a security point of view, and in memory/CPU shares) and offers the possibility to quickly and dynamically scale a service by allocating more equivalent VMs on different hardware. Of course, this comes at the price of adding one extra software layer between the NIC card and the application.

One such work, developed by Martins et al. \cite{clickos}, is ClickOS: it is based on the Xen hypervisor\footnote{http://www.xenproject.org} and leverages its para-virtualization capabilities: they run Click over a minimalistic OS (based on the Xen-shipped MiniOS), aside with a Linux installation running on the privileged dom0 domain: in order to boost performance, they relied on netmap \cite{netmap} on dom0, and wrote a custom virtual network driver for dealing with the communication between the hypervisor and the VMs. When running a sample IPv4 router on a single core and a 10 Gbps NIC, they obtained a throughput of little over 4 Mpps, corresponding to about 2 Gbps with minimal size frames (if measured at Ethernet \gls{PDU}).

Different architecture choices have lead Hwang et al. to the development of NetVM \cite{netvm}: the authors relied on QEMU\footnote{http://www.qemu.org} and KVM acceleration to run Linux on the host machine and the guests, using a DPDK-based userspace driver on the host; with some custom zero-copy host-guest communication structure, NetVM offers to the guest application a userspace library. Although they ported the userspace Click version to work in their setup, the authors recommend cascading services offered by multiple VMs exploiting the optimized VM-to-VM communication, in a way treating VMs similarly to Click components. NetVM also offers basic trust-group management capabilities. Testing their system on a machine with 12 cores and a 10 Gbps NIC card, the authors claim full speed with a simple L3 forwarder and about 6 Gbps (corresponding to about 9 \gls{Mpps}\todo{anche qui, controllare come lo misurano}) with a Click router.

\paragraph{} Despite the throughput numbers hinted above do not allow to compare performance across different studies (mainly due to the broad variety of hardware configurations used), these first experiences in software defined networking have proven that this technology could be already capable of managing an important part of our communication needs with the flexibility of software development. For this reason, it has the possibility to play a major role in the building of future internet architectures and network services, allowing new paradigms and protocols to be built and deployed in a much shorter time scale than what it took to build the current Internet protocol stack, starting with the flexibility to co-exist with traditional networking.

\section{Information-centric networking}
One such proposal for a new networking paradigm starts from the consideration that the modern web is growingly be used for content distribution and that the host-centric approach followed by IP can cause significant inefficiencies: for example, a popular content published by host A in figure TODO
and requested by clients B and C will have to travel twice through routers R1 and R2. Moreover, before being able to request the resource to host A, clients will need to query a name resolution service and obtain its address.

In contrast, the \glsfirst{ICN} paradigm aims at pushing the management of named resources into the network: in an ICN network, clients directly ask their router for a resource with a given name. The network will then take care of retrieving the requested resource regardless of where it's stored, and can exploit local cache at intermediate routers.

\todo[inline]{More details on other approaches? ICN? \url{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6231276} describes other approaches than the one I've focused on (CCN), should I mention them?}

There have been several approaches following this general idea, differing in several design choices. This work focuses on \gls{CCN} \cite{ccn}.

%\gls{ICN} routing is an interesting application where \gls{SDN} is attractive: while different approaches are under active development, software routing could allow to deploy such protocols and handle traffic at the scale of tens of Gbps on general-purpose hardwa

One interesting application where SDN is attractive is the development (and deployment) of middlebox software for \gls{ICN}, where routing and caching of data is often based on variable-length hierarchical resource identifiers: in this context, one critical bottleneck resides in the access to the routing table, that can grow much bigger than classical IP ones.
A key aspect to enable high-speed name-based routing is thus to optimize the data structures involved in the routing process: the \gls{FIB}, holding the name-interface association, which is queried for longest-prefix match; the \gls{PIT}, caching information of not-yet-evaded \emph{interest} packets received; and an index for locally-available cached content.

So et al. \cite{ndn_fast_dosresistant} proposed an algorithm to perform the longest-prefix match in the \gls{FIB} using a hash-table guaranteeing bounded number of reads in the worst-case, regardless of the number of components in the requested resource identifier. Their work also focuses on the optimization of the hash tables and the hashing function and on the possibility to partition the \gls{FIB} table among multiple processing cores.

In another work, Perino et al. \cite{caesar} have proposed Caesar, a router implementing a 2-stage longest-prefix match (LPM) algorithm based on a so-called prefix bloom filter: multiple bloom filters are queried to find (with the possibility of errors towards longer prefixes) the length of the prefix stored in the \gls{FIB} (i.e. the routing table), and a successive single lookup in a hash table finds the entry itself: thus, the required memory access operations for the LPM to two in most cases. Caesar also supports distributing the \gls{FIB} among multiple network processing units (NPUs) and GPU computation offloading. In this case, the target architecture is more powerful than the one this work focuses on.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{The Augustus content router}
\label{chap:augustus}

The \emph{Augustus} content router has been developed at Alcatel-Lucent Bell Labs\footnote{\url{https://www.alcatel-lucent.com/bell-labs}} as a software implementation of a \gls{CCN} router:
it is written in C and based on DPDK \cite{dpdk} for managing packet I/O directly in userspace.

Note that, at the moment, the router does not implement any protocol for the dissemination of routing information (control plane): instead, it implements the data plane packet processing and relies on routes being pre-loaded on the router. The reason is that, at this stage, the aim is to assess the performance of data plane routing in order to determine what could be the scale of a deployment using this technology.

This chapter starts providing an overview of the CCN routing protocol (section~\ref{sec:augustus.ccn}) and continues detailing the design choices and some implementation details for the involved data structures (sections~\ref{sec:augustus.cs} through \ref{sec:augustus.fib});
in particular, the \gls{PIT} implementation was found to have strong limitations and a new approach is proposed in section~\ref{sec:augustus.pit.new}.
Section~\ref{sec:augustus.numa} details the strategies adopted to better exploit multiprocessor architectures.
Finally, section~\ref{sec:augustus.click} presents a possible structure for a set of \emph{Click} elements implementing the same functionality. The full implementation and performance comparison is, however, left for a future work.

\section{CCN routing protocol}\label{sec:augustus.ccn}
\begin{algorithm}[htb]
%\begin{algorithm}[H]
  \DontPrintSemicolon
  \KwIn{$p$: ICN packet}
  \If{p.is\_interest()}{
    \input{extra/interest_routing_algo.tex}
  }
  \ElseIf{p.is\_data()}{
    \input{extra/data_routing_algo.tex}
  }
  \caption[CCN routing]{\textsc{CCN routing}}
  \label{algo:routing}
\end{algorithm}

The \gls{CCN} approach, first introduced by Jacobson et al. \cite{ccn} and adopted by the Named Data Networking initiative\footnote{\url{http://named-data.net/}}, relies on hierarchical names (e.g. \mono{/it/unitn/about/intro.mp4}) to address resources that fit a single packet (thus requiring to divide content into named chunks if it doesn't fit).

The content delivery is based on two packet types: \emph{interest} packets are sent by a client requesting for a resource with a given name, while \emph{data} packets carry the resource itself. Both packets hold the full name of the resource, together with other information aiding the routing procedure.
The Augustus router conforms to the specifications of an internet draft authored by the same research group at Bell labs \cite{icn-packet}.

Routing is stateful and works hop-by-hop: algorithm~\ref{algo:routing} outlines the basic routing procedure. When an interest packet is received, its name is first checked in the \glsfirst{CS}: if a cached data packet is found the router simply replies with the data, else it is checked against the \glsfirst{PIT}: if a match is found, the PIT entry is aggregated to the existing entry (i.e. the sender is added to the set of neighbours interested in the resource); if, instead, the name does not match a pending interest, the router searches for the longest prefix match in the \glsfirst{FIB} for the next-hop information about where the content can be found, and the interest is stored in the PIT and forwarded.
When a data packet is received it is first saved in the CS, in case it's later requested again; its name is then queried in the PIT: if a match is found, the data is forwarded to all neighbour hops where a previous interest for that data was received.

This way, the network holds in the routers' \gls{PIT}s a soft-state holding the reverse path for each interest that has not yet been evaded: this is a key difference with respect to stateless routing (e.g. IP) and poses strong requirements over the dimension and management of the data structure, as discussed later in section~\ref{sec:augustus.pit}

Moreover, although this was not included in the initial description, each interest packet is annotated with a random \emph{nonce} that is used to detect cyclic forwarding of the same packet and break the loop.


\section{Routing data structures}\label{sec:augustus.structures}
As also suggested by the results detailed in the next chapter (section~\ref{sec:test.multicore}), the main bottleneck for routing performance consists of memory access. Indeed, all the data structures implemented into the Augustus router are cache-aware, relying on cache-aligned memory areas grouping in a single x86\_64 cache line ($64$ bytes) information that is needed at once at access time.
This works best under the assumption that data structures do not fit in the processors' cache, thus cache space is the most scarce resource the router has to cope with.

Moreover, all data structures are allocated at bootstrap time, so that no expensive memory management procedure needs to be called during data plane routing operations.

It is worth noting that the \gls{PIT} and the \gls{CS} structures need to be updated online during router operations: by contrast, the \gls{FIB} can be operated read-only in the data plane, similarly to classical IP routing tables: updates can be computed asynchronously in the control plane and hot-swapped with the previous version, in the assumption that the difference between subsequent versions will be small and thus only a very small fraction of packets will be mis-routed during the update.

The remaining of this section provides some implementation details for the three data structures involved in the routing procedure.

\subsection{Content Store}\label{sec:augustus.cs}
\begin{figure}[htb]
  \begin{center}
    \frame{\includegraphics[width=1\textwidth]{img/cs_pit_sketch.png}}
    \caption[Sketch for the data structure for the CS and orignal PIT.]{Sketch of the data structure for the CS. The original PIT design also used the same layout with a hash table and a ring.}
    \label{fig:augustus.ht_ring}
  \end{center}
\end{figure}

The \gls{CS} holds the data packets that are available locally, implementing the in-network caching layer at the packet granularity. In the implementation, packets' content is never moved from the place where the \gls{DMA} operation placed it, in a memory area managed by the DPDK driver. Instead, the reference counters for the cached packets are increased so that the memory manager will not clean it up at sending time.

As outlined in section~\ref{sec:augustus.ccn}, the CS is always queried for exact matches in the name, so a hash table provides a simple and effective way to index cached structures. Moreover, the original designers chose to keep each hash table entry as small as possible by storing pointers to a ring (implemented as a circular array), which in turn stores the complete metadata and the pointer to the full packet, as depicted in figure~\ref{fig:augustus.ht_ring}: this allows them to manage collisions by squeezing seven entries into fixed-sized buckets which can be fit into a single cache line. This architecture brings the number of cache misses per query to two in most cases: one for fetching the bucket and one for fetching the full metadata from the ring.

In order to exploit this structure, the name hash works in two stages: first, a 32-bit \gls{CRC} sum of the name is computed, then the bucket index is obtained as the CRC module the HT size: after fetching the bucket, the full \gls{CRC} is compared to the ones stored in each entry in the matching bucket, until a match is found or the bucket end is reached. This way, the ring entry is only loaded from memory (and the full name is compared) only when the 32 bit hash matches; of course, in case of a collision in the CRC hash, this procedure may cause an extra cache miss.

\begin{figure}[htb]
  \captionsetup{type=lstlisting}
  %\centering
  \begin{sublstlisting}[t]{.5\linewidth}
    %\centering
  \begin{lstlisting}[language=c,escapechar=\%]
struct cs_ht_entry {
 bool busy;
 uint32_t crc;
 uint32_t ring_index;
};

struct cs_ring_entry {
 bool active;
 char full_name[MAX_NAME_LEN];
 struct dpdk_pkt *pkt;
 // index in HT for cleanup
 uint32_t bucket_index;
 uint8_t tab_in_bucket;
};
%
    \end{lstlisting}
    %\caption*{Slopes topology graph (Pinzolo).\\~}
    \caption{CS internal fields}\label{lst:augustus.cs}
  \end{sublstlisting}%
  \begin{sublstlisting}[t]{.5\linewidth}
    %\centering
  \begin{lstlisting}[language=c]
struct orig_pit_ht_entry {
 bool busy;
 uint32_t crc;
 uint32_t ring_index;
};
struct orig_pit_ring_entry {
 bool active;
 uint64_t expiry;
 uint64_t nonce_bf;
 char full_name[MAX_NAME_LEN];
 uint64_t interface_bitmask;
 // index in HT for cleanup
 uint32_t bucket_index;
 uint8_t tab_in_bucket;
};
    \end{lstlisting}
    %\caption*{Travel time distributions on Brenta slope for different groups types.}
    \caption{Original PIT internal fields}\label{lst:augustus.oldpit}
  \end{sublstlisting}
  \caption[CS and original PIT internal data structures fields]{Internal data structures fields for CS and PIT (simplified for clarity and brevity).}\label{lst:augustus.cs_oldpit}
\end{figure}

\subsection{Pending Interest Table}\label{sec:augustus.pit}
As the name suggests, the \gls{PIT} stores information for interests that have not been satisfied yet. This is the key structure for building the reverse path that a data packet will have to travel in order to reach the host requesting for it. Moreover, in case two clients request the same resource at about the same time, the PIT entries will be aggregated, thus building a multicast distribution tree for popular content.
As with the \gls{CS}, the PIT is always queried for exact matches.

Because a pending interest might stay so indefinitely (e.g. if the interest or data are lost upstream due to congestion), PIT entries need an expiry time that accounts for a worst-case round trip time from the router to the upstream resource. Meanwhile, long expiry times require the PIT to grow larger in order to fit all possible pending interests in the worst case.

During the experiments, an expiry time of $1$ second was chosen, as it was considered large enough for country-scale geographical installations (even if probably too tight for intercontinental links). Assuming a throughput of $5.5$ \gls{Mpps} (a little above the one actually measured, as detailed in chapter~\ref{chap:test}), this results in a PIT with $5.5$ millions entries, corresponding to about $500$ MB.

In its original implementation, the PIT layout was identical to the CS, with a stripped-down hash table and a ring storing most of the needed data. It obviously differs in the fields stored in the ring entry, as highlighted in listing\ref{lst:augustus.cs_oldpit}. The remaining parts of this section highlight the limitations of this approach and introduce an improved design overcoming them.

\subsubsection{PIT purging issue}\label{sec:augustus.pit.purge}
The described approach introduced the need for a PIT purging procedure: while the management of the ring structure is extremely simple and efficient when operated in a FCFS manner (as in the CS), it only allows a contiguous region of cells to be occupied. Thus, whenever a data packet comes that matches an entry other than  the bottom one, it has to be lazily deleted until all ``previous'' entries (i.e. the ones between the bottom pointer and the deleted one) are also deleted.  
Thus, the purging procedure was designed in order to clean up space from the entries at the bottom of the ring that were either expired or lazily deleted.

This procedure proved to work smoothly for the case where all interests were eventually satisfied. However, whenever even a single PIT entry came to expiry, it would prevent the purging procedure to be effective for $1$ second (the expiry time). In the meanwhile, when operating at the maximum rate, almost all the remaining entries would fill up and never get freed, blocked by the one bound to expire. Finally, after the expiration of the blocking entry, the purging procedure would free all the entries marked for deletion, up to the first valid one; at that point, the entries to be cleaned were often in the order of one million, causing the purge procedure to take $10$ to $15$ milliseconds to run: at the rate achieved by the router, this corresponds to about $13000$ to $20000$ packets that would be lost in a row.

\subsubsection{Improved data structure design}\label{sec:augustus.pit.new}

\begin{figure}[htb]
  \begin{center}
    \frame{\includegraphics[width=1\textwidth]{img/new_pit_sketch.png}}
    \caption[Sketch for the improved PIT data structure]{Sketch for the improved PIT data structure.}
    \label{fig:augustus.newpit}
  \end{center}
\end{figure}

\begin{figure}[htb]
  \captionsetup{type=lstlisting}
  %\centering
  \begin{sublstlisting}[t]{.5\linewidth}
    %\centering
  \begin{lstlisting}[language=c]
struct pit_index_entry {
 bool busy;
 uint32_t crc;
 uint64_t expiry;
};
struct pit_body_entry {
 uint64_t nonce_bf;
 char full_name[MAX_NAME_LEN];
 uint64_t interface_bitmask;
};
    \end{lstlisting}
    %\caption*{Slopes topology graph (Pinzolo).\\~}
    \caption{Improved PIT internal fields}\label{lst:augustus.newpit}
  \end{sublstlisting}%
  \begin{sublstlisting}[t]{.5\linewidth}
    %\centering
  \begin{lstlisting}[language=c]
struct fib_ht_entry {
 bool busy;
 uint32_t crc;
 uint32_t array_index;
};

struct fib_array_entry {
 char full_prefix[MAX_NAME_LEN];
 uint8_t interface_id;
};
    \end{lstlisting}
    %\caption*{Travel time distributions on Brenta slope for different groups types.}
    \caption{FIB internal fields}\label{lst:augustus.fib}
  \end{sublstlisting}
  \caption[Internal data structures fields for the improved PIT and the FIB]{Internal data structures fields for the improved PIT and the FIB (simplified for clarity and brevity).}\label{lst:augustus.newpit_fib}
\end{figure}

In order to overcome this issue, a new layout for the PIT was designed and implemented into the router: as depicted in figure~\ref{fig:augustus.newpit}, the new design relies solely on a hash table. Nevertheless, following the design principle that guided the original development, the first cache line of each bucket is used as an index for the ones to come: as detailed in listing~\ref{lst:augustus.newpit}, the bucket index contains the full 32 bit CRC hash, one bit indicating the slot's occupancy and the expiry timestamp. This way, the new structure keeps the property that, except for CRC collisions, a single cache miss is enough to determine whether a name is present as a valid entry in the PIT.

Note that this new structure does not require a periodic purge operation: after loading the bucket index from main memory, the lookup procedure may scan the whole bucket index with no additional memory operations, treating expired entries as empty slots.

Section~\ref{sec:test.pit} presents a comparison of the packet loss profile before and after introducing the new PIT implementation.

\subsection{Forwarding Information Base}\label{sec:augustus.fib}
The \gls{FIB} is the structure that, similarly to an IP routing table, holds next-hop information for all known name prefixes and is read-only during data plane routing. Comparing to IP routing tables, however, the \gls{FIB} needs to span a much larger addressing space.

Also the basic part of the FIB structure is similar to the other data structures presented so far, as outlined in listing~\ref{lst:augustus.fib}: a stripped-down hash tables with pointers to an external array where the rest of the data is stored. Note that, this time, there is no need for any special management for the external array, as it will be filled sequentially and, as long as the data plane is concerned, entries are never updated nor deleted.

Moreover, the complete implementation of the Augustus router employs an additional \emph{prefix bloom filter} for faster longest prefix lookups: as detailed in the presenting the Caesar router by Perino et al. \cite{caesar}, which provided a starting point for the fully-software reimplementation in Augustus. This structure relies on multiple bloom filters in order to determine (with the possibility of infrequent errors) the length of the prefix that should be looked up in the hash table.
Nevertheless, because this technology was going through the patenting process, the implementation was not disclosed and we could not try it.

Because we could not experiment with its full implementation, the \gls{FIB} was never put under stress throughout the experimental evaluation described in chapter\ref{chap:test}.

\section{Multi-threading and NUMA awareness}\label{sec:augustus.numa}
The Augustus router targets modern servers that are most often equipped with multiple CPU sockets, each containing multiple processing cores. The management of processing cores is aided by the DPDK abstraction library, which natively supports multi-threading and requires to pin at initialization time each thread (called a logical core, or \mono{lcore} in DPDK) to a physical processor: this prevents unneeded context switches, better exploiting local caches.

When multiple CPU sockets are installed on a server, it is common that separate memory banks are directly attached to each core, resulting in a \glsfirst{NUMA} architecture: each processing core has a most direct access to memory allocated on a bank on the same socket (called NUMA node), while access to ``remote'' memory is slower and may cause extra bus conflicts.\todo{numbers...}

Moreover, in the context of high-speed packet routing, it is not feasible to manage shared data structures with semaphores, as they introduce an excessive overhead: whenever possible, thread-private data structures are used for read/write operations and shared structures are accessed read-only by all-but-one threads.

In the Augustus router, both the \gls{PIT} and \gls{CS} structures are thread-private and are allocated on the same socket where the thread runs, while the \gls{FIB} is accessed read-only but is nevertheless replicated on each NUMA node, so that local memory access is always possible.
However, separating the \gls{PIT} and \gls{CS} among the threads poses a strong correctness issue: what if a data packet with a name is handled by a different thread than its corresponding interest packet? If this happens, the thread handling the data packet will not find a matching pending interest and will drop the packet as spurious. The same goes for successive interests for the same name, that should result in either a CS hit or in a PIT aggregation.

To overcome this issue, the hardware multiqueue system available in modern NICs is configured to inspect the incoming packets and read a header field holding a hash of the content name, so that it will dispatch packets referring to the same name consistently to the same hardware queue: each queue is polled by a single thread, guaranteeing that two packets with the same name will be delivered to the same thread.

\section{Click module port}\label{sec:augustus.click}
\lstinputlisting[float=hbt, captionpos=b, label=lst:augustus.icn, caption=Sample Click configuration file using the API under development]{extra/icnrouter.click.txt}

One limitation posed by the choice of a implementing a standalone software router is that it can not easily coexist on the same hardware (sharing the network cards) with other routing applications. The to main ways to overcome this limitation could be either running the software in a virtual machine, or integrate it as a plug-in into an existing routing framework. While virtualization of network functions is an active research topic and reachable performance could be of the same order of magnitude, the second approach   the original developers showed a strong interest in porting the router to the \emph{Click} modular router: 
Alongside with the evaluation of the performance of the standalone router implementation described so far, 
\todo[inline]{Quick description and design decisions for the click elements' API.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Performance evaluation}
\label{chap:test}

\section{Testing environment}\label{sec:test.env}
The experimental setup was composed of two twin machines, each equipped with two 10 Gbps Ethernet ports:
table \ref{tab:test.hw} summarises their hardware components.

\begin{table}[tb]
  \begin{center}
    \begin{tabular}{ll}
      \toprule
      %\midrule
      CPUs   & 2 $\times$ Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz \\
      Memory & 4 $\times$ 16 GB @ 1866 MHz\\
      NICs   & 2 $\times$ Intel 82599ES 10-Gigabit SFI/SFP+ Network Connection \\
             & 2 $\times$ Intel I350 Gigabit Network Connection \\
      \bottomrule
    \end{tabular}
  \end{center}
  %\vspace{-.5cm} % prevents latex from preferring to put this in a blank page
  \caption{Hardware configuration for the two test servers}
  \label{tab:test.hw}
\end{table}

Only the 10 Gbps ports were used for the measurements: corresponding ports in the two machines were connected with passive copper cables attached to the SPF+ ports. On each server, one Gigabit port was used for a management connection, while the remaining port was left unused.

The machines were running Linux 3.16. Following installation recommendation by the DPDK authors, the command line for the kernel provided the allocation of 1 GB huge pages, which were then mounted with the dedicated pseudo-filesystem.%
\footnote{\url{https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt}}
%\footnote{\url{https://web.archive.org/web/20150906011201/https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt}}

\todo[inline]{Picture of the servers' back panel and network connector}


\section{Accounting for Ethernet overhead}\label{sec:test.overhead}
\todo[inline]{just 1 or 2 paragraph describing the dashed line in the plots}

\section{Traffic generator}\label{sec:test.traffgen}
\todo[inline]{Roughly describe the traffic generator/echo server}

\subsection{Generation performance}
\todo[inline]{Present the results for the cases with the generator loop connection}

\section{Single-threaded routing}

\section{Multi-threaded routing}\label{sec:test.multicore}

\subsection{CPUs and memory layout}\label{sec:test.multicore.layout}
\todo[inline]{Describe and sketch the layout.}

\subsection{Performance by core mapping}\label{sec:test.multicore.performance}

\section{Evaluation of the new PIT design}\label{sec:test.pit}

%  SIMPLE PICTURE
%\begin{figure}[htb]
%  \begin{center}
%    \frame{\includegraphics[width=.6\textwidth]{img/maps/pinzolo_slopes.pdf}}
%    \caption[Available maps for Pinzolo ski area]{Available maps for Pinzolo ski area.}
%    \label{fig:map-input}
%  \end{center}
%\end{figure}

% CITE
%In order to achieve this, the map was converted to a 0/1 raster map and the algorithm described in \cite{rthin-algorithm} was run on the rasterized map. %, obtaining the map represented in Figure~\ref{fig:map-thinned}.


% TEXTTTT (MONO)
%In particular, \texttt{v.to.rast} module was , single empty pixels surrounded by four filled pixels were forced to be filled.
%However, because it doesn't natively handle topology maps, the obtained refined map was imported back to GRASS GIS, where the topology was finalized and explicit nodes were created using \texttt{v.net} with \texttt{operation\,=\allowbreak\,nodes} (accompanied by \texttt{v.db.addtable} and \texttt{v.category} for properly setting up the attribute table), and spatial attributes like length of edges and altitude of nodes were attached to the respective features.

% ALGORITHM
\begin{comment}
\begin{algorithm}[htb]
%\begin{algorithm}[H]
  \DontPrintSemicolon
  \KwIn{$passages$}
  $passages.sort\_by(\lambda p . new~Couple(p.skipass, p.timestamp))$\;
  $prev := null$\;
  \ForEach{$p \in passages$}{
    $is\_descent := \backslash$\;
    \Indp
      $prev \neq null  \wedge  prev.skipass = p.skipass~\backslash \wedge~prev.day = p.day$\;
    \Indm
    \If{$is\_descent$}{
      \tcp{process descent identified by $prev$ and $p$}
    }
    $prev := p$\;
  }
  \caption[Descents identification]{\textsc{Descents identification}}
  \label{algo:descents}
\end{algorithm}
\end{comment}

\begin{comment}
\begin{table}[tb]
  \begin{center}
    \begin{tabular}{lrrrrr}
      \toprule
        \multicolumn{1}{c}{SD pair} &
        \multicolumn{1}{c}{\specialcell[3cm]{Descents\\percentage}} &
        \multicolumn{1}{c}{\specialcell[3cm]{Log-\\normal}} &
        \multicolumn{1}{c}{Gamma} &
        \multicolumn{1}{c}{Beta} &
        \multicolumn{1}{c}{\specialcell[3cm]{Generalized\\gamma}}\\
      \midrule
      \csvreader[%head to column names,
                 head = true,
                 before line = \\,
                 before first line = {},
                ]
                {tables/fitting_quality.csv}{}{\csvlinetotablerow}
      \\\bottomrule
    \end{tabular}
  \end{center}
  \vspace{-.5cm} % prevents latex from prefering to put this in a blank page
  \caption[Travel time fitting quality]{Fitting quality for some common distributions for every valid SD pair, after applying lunch filtering. SD pairs are identified by the node labels in fig, the second column indicates the percentage of descents for that SD pair with respect to total valid descents. Best fitting values for each row are in bold.}
  \label{tab:traffic-lognorm-fitting}
\end{table}
\end{comment}


\begin{comment}
\begin{figure}[hbt]
  \begin{center}
    %\includegraphics[width=\textwidth]{img/traffic/brenta_groups.pdf}
    \begin{tikzpicture}
      \node (hist) {\includegraphics[width=\textwidth]{img/traffic/brenta_groups.pdf}};
      \node (bwplot) at (hist.north east) [anchor=north east,yshift=-.8cm,xshift=-.9cm]
        {\includegraphics[width=.5\textwidth]{img/traffic/brenta_groups_bw.pdf}};
    \end{tikzpicture}
    \caption[Travel times distributions by group type]{Travel times distributions by group type on Brenta slope. Top panel show the travel time histograms for the identified group types, bottom panel shows a zoom of the same plot on low values. In the box, the representation of the same data as a box plot. Gray lines are log-normal best fitting curves. Note that, in this case, last 5 percentiles were removed independently from each group.}
% not-TODO: provare con il fitting anche sulle curve singole, che sembrano simili?
    \label{fig:traveltimes-groups}
  \end{center}
\end{figure}
\end{comment}


\chapter{Conclusions}

This work approached the analysis of skiing traffic with the construction of a novel framework: it includes the needed geographical pre-processing tools and implements a set of ad-hoc algorithms for skiing traffic analysis.

The implemented functions were run on the $2\,521\,385$ lift rides case study dataset: this way, a first system of statistical results was obtained.

Throughout this process, it was important to focus on skiing groups: in fact, the implemented grouping algorithm highlights that nearly $90\%$ of descents are taken by skiers moving in groups.
Furthermore, an application of traffic analysis to accidents epidemiology was investigated with the introduction of a traffic-based normalization of accidents data which led to the capability of constructing normalized risk analysis for parts of the case study area.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Future work}
\label{sec:future-work}

 One limitation of the described algorithms is that they are not able to determine the distribution of skiers over the possible slopes that connect two nodes. A possible approach to overcome this limitation would be to distribute a mobile application for tracking skiers in their movements along slopes and lifts using the phone's GPS sensor; of course, the application would offer some services like displaying some basic analysis of the user's tracks so that more skiers would be interested in using it. This way, skiers could be tracked during their descents, and their paths could be the base for building or validating a model for the distributions of skiers in the whole ski area.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\listoffigures
{
  %\let\cleardoublepage\clearpage  % this prevents 2 blank pages between listof*
%  \listoftables

%  \cleardoublepage
%  \phantomsection
%  \addcontentsline{toc}{chapter}{List of Algorithms}
%  \listofalgorithms

%  and, moreover: \lstlistoflistings
}

\bibliography{davide_kirchner_thesis}


%\printindex  % don't know what this is for, was suggested for glossary...
\printglossaries


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
~\newpage ~\newpage

\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}


\end{document}
